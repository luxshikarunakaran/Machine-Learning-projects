{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNTgkpQU9U/G/wAudIggdTv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"r1GwNyQzWooF"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, Model, Sequential\n","from tensorflow.keras.layers import Conv2D, BatchNormalization, MaxPooling2D, Dropout, Flatten, Dense, GlobalAveragePooling2D, Input, UpSampling2D, concatenate\n","from tensorflow.keras.applications import EfficientNetB0, MobileNetV3Large, ResNet50\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","import tensorflow_hub as hub\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc, confusion_matrix\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import time\n","import cv2\n","\n","# Constants\n","IMAGE_SIZE = 224\n","N_CLASSES = 3  # Normal, Adenocarcinoma, Squamous Cell Carcinoma\n","BATCH_SIZE = 32\n","MODEL_ACCURACY = 80  # Example threshold for reliable predictions (adjust based on best model's accuracy)\n","class_labels = {0: 'Normal', 1: 'Adenocarcinoma', 2: 'Squamous Cell Carcinoma'}\n","\n","# 1. Preprocessing Technique\n","def preprocess_image(image):\n","    image = tf.image.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n","    image = image / 255.0\n","    return image\n","\n","def preprocess_for_prediction(image):\n","    img = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n","    img = img / 255.0\n","    img = np.expand_dims(img, axis=0)\n","    return convert_to_rgb(img)\n","\n","def convert_to_rgb(images):\n","    return tf.image.grayscale_to_rgb(images) if images.shape[-1] == 1 else images\n","\n","def create_data_generator():\n","    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n","        preprocessing_function=preprocess_image,\n","        rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True\n","    )\n","    valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function=preprocess_image)\n","    train_generator = train_datagen.flow_from_directory(\n","        'path/to/train', target_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE, class_mode='sparse'\n","    )\n","    valid_generator = valid_datagen.flow_from_directory(\n","        'path/to/val', target_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE, class_mode='sparse'\n","    )\n","    return train_generator, valid_generator\n","\n","# 2. Model Definitions\n","def build_cnn_model(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), n_classes=N_CLASSES):\n","    model = Sequential([\n","        tf.keras.layers.Input(shape=input_shape),\n","        Conv2D(32, (3, 3), padding='same', activation='relu'), BatchNormalization(),\n","        Conv2D(32, (3, 3), padding='same', activation='relu'), BatchNormalization(),\n","        MaxPooling2D((2, 2)), Dropout(0.25),\n","        Conv2D(64, (3, 3), padding='same', activation='relu'), BatchNormalization(),\n","        Conv2D(64, (3, 3), padding='same', activation='relu'), BatchNormalization(),\n","        MaxPooling2D((2, 2)), Dropout(0.25),\n","        Conv2D(128, (3, 3), padding='same', activation='relu'), BatchNormalization(),\n","        Conv2D(128, (3, 3), padding='same', activation='relu'), BatchNormalization(),\n","        MaxPooling2D((2, 2)), Dropout(0.25),\n","        Flatten(), Dense(512, activation='relu'), BatchNormalization(), Dropout(0.5),\n","        Dense(n_classes, activation='softmax')\n","    ])\n","    return model\n","\n","def build_efficientnet_model(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), n_classes=N_CLASSES):\n","    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n","    base_model.trainable = False\n","    inputs = tf.keras.Input(shape=input_shape)\n","    x = base_model(inputs, training=False)\n","    x = GlobalAveragePooling2D()(x)\n","    x = Dense(128, activation='relu')(x)\n","    x = Dropout(0.5)(x)\n","    outputs = Dense(n_classes, activation='softmax')(x)\n","    return Model(inputs, outputs)\n","\n","def build_mobilenet_model(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), n_classes=N_CLASSES):\n","    base_model = MobileNetV3Large(include_top=False, weights='imagenet', input_shape=input_shape)\n","    base_model.trainable = False\n","    model = Sequential([\n","        base_model, GlobalAveragePooling2D(), Dense(128, activation='relu'), Dropout(0.5),\n","        Dense(n_classes, activation='softmax')\n","    ])\n","    return model\n","\n","def build_resnet_model(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), n_classes=N_CLASSES):\n","    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n","    base_model.trainable = False\n","    inputs = tf.keras.Input(shape=input_shape)\n","    x = base_model(inputs, training=False)\n","    x = GlobalAveragePooling2D()(x)\n","    x = Dense(128, activation='relu')(x)\n","    x = Dropout(0.5)(x)\n","    outputs = Dense(n_classes, activation='softmax')(x)\n","    return Model(inputs, outputs)\n","\n","class SwinTransformerLayer(layers.Layer):\n","    def __init__(self, hub_url, **kwargs):\n","        super(SwinTransformerLayer, self).__init__(**kwargs)\n","        self.hub_layer = hub.KerasLayer(hub_url, trainable=False)\n","    def call(self, inputs, training=None):\n","        return self.hub_layer(inputs)\n","\n","def build_swin_transformer_model(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), n_classes=N_CLASSES):\n","    inputs = Input(shape=input_shape)\n","    swin_transformer_url = \"https://tfhub.dev/sayakpaul/swin_tiny_patch4_window7_224/1\"\n","    x = SwinTransformerLayer(swin_transformer_url)(inputs)\n","    x = Dense(128, activation='relu')(x)\n","    x = Dropout(0.5)(x)\n","    outputs = Dense(n_classes, activation='softmax')(x)\n","    return Model(inputs=inputs, outputs=outputs)\n","\n","def build_unet_model(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), n_classes=N_CLASSES):\n","    inputs = Input(input_shape)\n","    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n","    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n","    p1 = MaxPooling2D((2, 2))(c1)\n","    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n","    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n","    p2 = MaxPooling2D((2, 2))(c2)\n","    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n","    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n","    p3 = MaxPooling2D((2, 2))(c3)\n","    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n","    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n","    p4 = MaxPooling2D((2, 2))(c4)\n","    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n","    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n","    u6 = UpSampling2D((2, 2))(c5)\n","    u6 = concatenate([u6, c4])\n","    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n","    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n","    u7 = UpSampling2D((2, 2))(c6)\n","    u7 = concatenate([u7, c3])\n","    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n","    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n","    u8 = UpSampling2D((2, 2))(c7)\n","    u8 = concatenate([u8, c2])\n","    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n","    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n","    u9 = UpSampling2D((2, 2))(c8)\n","    u9 = concatenate([u9, c # Build U-Net model for classification\n","def build_unet_model(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), n_classes=N_CLASSES):\n","    inputs = Input(input_shape)\n","    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n","    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n","    p1 = MaxPooling2D((2, 2))(c1)\n","    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n","    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n","    p2 = MaxPooling2D((2, 2))(c2)\n","    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n","    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n","    p3 = MaxPooling2D((2, 2))(c3)\n","    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n","    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n","    p4 = MaxPooling2D((2, 2))(c4)\n","    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n","    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n","    u6 = UpSampling2D((2, 2))(c5)\n","    u6 = concatenate([u6, c4])\n","    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n","    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n","    u7 = UpSampling2D((2, 2))(c6)\n","    u7 = concatenate([u7, c3])\n","    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n","    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n","    u8 = UpSampling2D((2, 2))(c7)\n","    u8 = concatenate([u8, c2])\n","    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n","    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n","    u9 = UpSampling2D((2, 2))(c8)\n","    u9 = concatenate([u9, c1])\n","    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n","    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n","    x = GlobalAveragePooling2D()(c9)\n","    x = Dense(128, activation='relu')(x)\n","    x = Dropout(0.5)(x)\n","    outputs = Dense(n_classes, activation='softmax')(x)\n","    model = Model(inputs, outputs)\n","    return model\n","\n","# 3. Training and Evaluation\n","def train_and_evaluate_model(model, model_name, train_generator, valid_generator):\n","    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","    checkpointer = ModelCheckpoint(f'{model_name}.keras', verbose=1, save_best_only=True)\n","    early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n","\n","    start_time = time.time()\n","    history = model.fit(\n","        train_generator.map(lambda x, y: (convert_to_rgb(x), y)),\n","        epochs=25, validation_data=valid_generator.map(lambda x, y: (convert_to_rgb(x), y)),\n","        callbacks=[checkpointer, early_stopping], verbose=1\n","    )\n","    training_time = time.time() - start_time\n","\n","    # Evaluate on validation set\n","    val_preds = model.predict(valid_generator)\n","    val_labels = np.concatenate([y for x, y in valid_generator], axis=0)\n","    val_preds_classes = np.argmax(val_preds, axis=1)\n","\n","    # Metrics\n","    accuracy = accuracy_score(val_labels, val_preds_classes)\n","    precision = precision_score(val_labels, val_preds_classes, average='weighted')\n","    recall = recall_score(val_labels, val_preds_classes, average='weighted')  # Sensitivity\n","    f1 = f1_score(val_labels, val_preds_classes, average='weighted')\n","    cm = confusion_matrix(val_labels, val_preds_classes)\n","    specificity = np.mean([cm[i, i] / cm[i].sum() for i in range(N_CLASSES) if cm[i].sum() > 0])\n","\n","    # ROC Curve\n","    fpr, tpr, roc_auc = {}, {}, {}\n","    for i in range(N_CLASSES):\n","        fpr[i], tpr[i], _ = roc_curve(val_labels == i, val_preds[:, i])\n","        roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","    return {\n","        'model_name': model_name, 'history': history.history, 'training_time': training_time,\n","        'accuracy': accuracy, 'precision': precision, 'recall': recall, 'f1': f1, 'specificity': specificity,\n","        'fpr': fpr, 'tpr': tpr, 'roc_auc': roc_auc, 'model': model\n","    }\n","\n","# 4. Detection and Prediction Logic\n","def detect_and_predict(image_path, classifier):\n","    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","    if image is None:\n","        print(\"Error: Unable to load the image. Please check the file format and path.\")\n","        return None, None\n","\n","    blurred = cv2.GaussianBlur(image, (5, 5), 0)\n","    _, binary = cv2.threshold(blurred, 50, 255, cv2.THRESH_BINARY)\n","    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    output_image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n","    predictions = []\n","\n","    for contour in contours:\n","        area = cv2.contourArea(contour)\n","        if area > 100:\n","            x, y, w, h = cv2.boundingRect(contour)\n","            cv2.rectangle(output_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n","            cropped_image = image[y:y + h, x:x + w]\n","            preprocessed_image = preprocess_for_prediction(cropped_image)\n","            confidence_scores = classifier.predict(preprocessed_image)[0]\n","            predicted_class_index = np.argmax(confidence_scores)\n","            predicted_class = class_labels[predicted_class_index]\n","            confidence = round(100 * confidence_scores[predicted_class_index], 2)\n","            predictions.append((predicted_class, confidence))\n","            cv2.putText(output_image, f\"{predicted_class} ({confidence}%)\", (x, y - 10),\n","                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n","\n","    plt.figure(figsize=(10, 5))\n","    plt.subplot(1, 2, 1)\n","    plt.title('Original CT Scan')\n","    plt.imshow(image, cmap='gray')\n","    plt.axis('off')\n","\n","    plt.subplot(1, 2, 2)\n","    plt.title('Detected Areas with Predictions')\n","    plt.imshow(output_image)\n","    plt.axis('off')\n","    plt.show()\n","\n","    for i, (pred_class, conf) in enumerate(predictions):\n","        print(f'Detected area {i + 1}: {pred_class} with confidence {conf}%')\n","\n","    if predictions:\n","        reliable_predictions = [(p, c) for p, c in predictions if c >= MODEL_ACCURACY]\n","        if reliable_predictions:\n","            final_pred_class, final_conf = max(reliable_predictions, key=lambda x: x[1])\n","            print(f'Final prediction result (considering {MODEL_ACCURACY}% model accuracy): '\n","                  f'{final_pred_class} with confidence {final_conf}%')\n","            cancer_types = ['adenocarcinoma', 'large_cell_carcinoma', 'squamous_cell_carcinoma']\n","            if final_pred_class.lower() in cancer_types:\n","                print(f\"Cancer detected: {final_pred_class} with confidence {final_conf}% \"\n","                      f\"(model accuracy: {MODEL_ACCURACY}%)\")\n","            else:\n","                print(f\"No cancer detected: {final_pred_class} with confidence {final_conf}% \"\n","                      f\"(model accuracy: {MODEL_ACCURACY}%)\")\n","            print(f\"The image is classified as: {final_pred_class} with confidence {final_conf}%\")\n","        else:\n","            print(f\"No reliable predictions above model accuracy threshold ({MODEL_ACCURACY}%)\")\n","            print(\"The image type cannot be confidently determined due to low confidence scores.\")\n","    else:\n","        print(\"No significant areas detected.\")\n","        print(\"The image type cannot be determined due to no detectable areas.\")\n","\n","    return predictions, output_image\n","\n","# Main Execution\n","train_generator, valid_generator = create_data_generator()\n","models = [\n","    (build_cnn_model(), 'CNN'),\n","    (build_efficientnet_model(), 'EfficientNetB0'),\n","    (build_mobilenet_model(), 'MobileNetV3'),\n","    (build_resnet_model(), 'ResNet50'),\n","    (build_swin_transformer_model(), 'SwinTransformer'),\n","    (build_unet_model(), 'UNet')\n","]\n","\n","results = []\n","for model, name in models:\n","    result = train_and_evaluate_model(model, name, train_generator, valid_generator)\n","    results.append(result)\n","\n","# Comparison of Models\n","print(\"\\nModel Comparison:\")\n","print(f\"{'Model':<20} {'Accuracy':<10} {'Sensitivity':<12} {'Specificity':<12} {'Training Time (s)':<18}\")\n","for result in results:\n","    print(f\"{result['model_name']:<20} {result['accuracy']:.4f}    {result['recall']:.4f}      {result['specificity']:.4f}      {result['training_time']:.2f}\")\n","\n","# Plot ROC Curves\n","plt.figure(figsize=(10, 8))\n","for result in results:\n","    for i in range(N_CLASSES):\n","        plt.plot(result['fpr'][i], result['tpr'][i], label=f\"{result['model_name']} Class {i} (AUC = {result['roc_auc'][i]:.2f})\")\n","plt.plot([0, 1], [0, 1], 'k--')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC Curves')\n","plt.legend(loc='best')\n","plt.show()\n","\n","# Find Best Model\n","best_model_result = max(results, key=lambda x: x['accuracy'])\n","best_model_name = best_model_result['model_name']\n","best_model = best_model_result['model']\n","print(f\"\\nBest Model: {best_model_name} with Accuracy: {best_model_result['accuracy']:.4f}\")\n","\n","# Detection and Prediction on CT Scan\n","image_path = '/content/drive/MyDrive/Data/test/adenocarcinoma/000109 (2).png'\n","predictions, output_image = detect_and_predict(image_path, best_model)"]}]}