{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNZsOW2/ZrK9aVIu+heIOy/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"LmqpqHJ8tv0K"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.applications.resnet import preprocess_input\n","\n"]},{"cell_type":"code","source":["# Paths to your dataset\n","train_path = '/content/drive/MyDrive/Data/train'\n","valid_path = '/content/drive/MyDrive/Data/valid'\n","test_path = '/content/drive/MyDrive/Data/test'\n","\n"],"metadata":{"id":"TZ2Jgsf7t3_B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Constants\n","IMAGE_SIZE = 224\n","N_CLASSES = 4\n","BATCH_SIZE = 32\n","CHANNELS = 1\n","\n"],"metadata":{"id":"n-oEXRYIt6zi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Data Preprocessing\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=10,\n","    width_shift_range=0.3,\n","    height_shift_range=0.3,\n","    shear_range=0.2,\n","    zoom_range=0.1,\n","    horizontal_flip=True,\n","    vertical_flip=True,\n","    preprocessing_function=preprocess_input\n",")\n","\n","valid_datagen = ImageDataGenerator(rescale=1./255)\n","test_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_generator = tf.keras.preprocessing.image_dataset_from_directory(\n","    train_path,\n","    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n","    batch_size=BATCH_SIZE,\n","    color_mode=\"grayscale\",\n","    shuffle=True\n",")\n","\n","valid_generator = tf.keras.preprocessing.image_dataset_from_directory(\n","    valid_path,\n","    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n","    batch_size=BATCH_SIZE,\n","    color_mode=\"grayscale\",\n","    shuffle=True\n",")\n","\n","test_generator = tf.keras.preprocessing.image_dataset_from_directory(\n","    test_path,\n","    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n","    batch_size=BATCH_SIZE,\n","    color_mode=\"grayscale\",\n","    shuffle=True\n",")\n","\n","# Store class names\n","class_names = train_generator.class_names\n","\n"],"metadata":{"id":"ih0UUR1St91K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to format class names with spacing\n","def format_class_name(class_name):\n","    return class_name.replace(\".\", \" \").replace(\"_\", \" \").title()\n","\n","# Display Augmented Images with Class Names\n","def display_augmented_images(generator, num_images=6):\n","    for images, labels in generator.take(1):\n","        plt.figure(figsize=(12, 8))\n","        for i in range(num_images):\n","            plt.subplot(2, 3, i + 1)\n","            plt.imshow(images[i].numpy().astype(\"uint8\"), cmap='gray')\n","            plt.axis('off')\n","            class_label = format_class_name(class_names[labels[i].numpy()])\n","            plt.title(class_label, pad=20, fontsize=10, fontweight=\"bold\", wrap=True)\n","        plt.suptitle('Augmented Grayscale Images', fontsize=14, y=1.05)\n","        plt.tight_layout(pad=3.0)\n","        plt.show()\n","\n","# Display augmented images\n","display_augmented_images(train_generator)\n"],"metadata":{"id":"y7Z568l2uBXK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Build the ResNet50 model\n","base_model = ResNet50(include_top=False, weights='imagenet', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n","base_model.trainable = False  # Freeze the base model\n","\n","# Add custom layers on top of the base model\n","model = Sequential([\n","    base_model,\n","    GlobalAveragePooling2D(),\n","    Dense(128, activation='relu'),\n","    Dropout(0.5),\n","    Dense(N_CLASSES, activation='softmax')\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Callbacks\n","checkpointer = ModelCheckpoint('chestmodel.keras', verbose=1, save_best_only=True)\n","early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n","\n","# Train the model\n","history = model.fit(\n","    train_generator,\n","    epochs=50,\n","    validation_data=valid_generator,\n","    callbacks=[checkpointer, early_stopping]\n",")\n","\n"],"metadata":{"id":"709I90z6uFLy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate the model\n","result = model.evaluate(test_generator)\n","print(f'Test Loss: {result[0]}, Test Accuracy: {result[1]}')\n","\n"],"metadata":{"id":"Rjm9LcwTuIHJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predictions\n","y_true = test_generator.classes\n","y_pred = model.predict(test_generator)\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","\n","# Model Evaluation\n","# 1. Classification Report\n","print(\"Classification Report:\")\n","print(classification_report(y_true, y_pred_classes))\n","\n"],"metadata":{"id":"4zGA6uchuK8B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 2. Confusion Matrix\n","conf_matrix = confusion_matrix(y_true, y_pred_classes)\n","plt.figure(figsize=(10, 7))\n","sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys())\n","plt.ylabel('Actual')\n","plt.xlabel('Predicted')\n","plt.title('Confusion Matrix')\n","plt.show()\n","\n"],"metadata":{"id":"7mOtp0b5uNXB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 3. ROC Curve\n","fpr = {}\n","tpr = {}\n","roc_auc = {}\n","for i in range(N_CLASSES):\n","    fpr[i], tpr[i], _ = roc_curve(y_true == i, y_pred[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","# Plot ROC curves\n","plt.figure()\n","for i in range(N_CLASSES):\n","    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for class %d' % (roc_auc[i], i))\n","plt.plot([0, 1], [0, 1], 'k--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic')\n","plt.legend(loc=\"lower right\")\n","plt.show()\n","\n"],"metadata":{"id":"L6_3kxVBuPPh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Displaying some predictions\n","plt.figure(figsize=(12, 12))\n","for images, labels in test_generator.take(1):\n","    for i in range(9):\n","        ax = plt.subplot(3, 3, i + 1)\n","        plt.imshow(images[i].numpy().astype(\"uint8\"), cmap='gray')\n","        plt.title(f'Predicted: {y_pred_classes[i]}, Actual: {y_true[i]}')\n","        plt.axis('off')\n","plt.suptitle('Predictions on Test Images')\n","plt.show()\n","\n"],"metadata":{"id":"bEcZnQe5uRth"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Image Detection with CNN\n","def simulate_detection(image):\n","    height, width = image.shape[0:2]\n","    box = [0.1 * width, 0.1 * height, 0.8 * width, 0.8 * height]  # [x1, y1, x2, y2]\n","    confidence = np.random.rand()  # Random confidence score\n","    return box, confidence\n","\n","# Display detection results\n","for images_batch, _ in test_generator.take(1):\n","    for i in range(3):\n","        plt.imshow(images_batch[i].reshape(IMAGE_SIZE, IMAGE_SIZE), cmap='gray')\n","        box, confidence = simulate_detection(images_batch[i])\n","        plt.gca().add_patch(plt.Rectangle((box[0], box[1]), box[2] - box[0], box[3] - box[1], fill=False, color='red', linewidth=2))\n","        plt.title(f'Confidence: {confidence:.2f}')\n","        plt.axis('off')\n","        plt.show()\n","\n"],"metadata":{"id":"sKA7BtQFuUO7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Image Segmentation with CNN\n","def build_segmentation_model(input_shape):\n","    inputs = tf.keras.Input(shape=input_shape)\n","    c1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n","    c1 = Conv2D(32, (3, 3), activation='relu', padding='same')(c1)\n","    p1 = MaxPooling2D((2, 2))(c1)\n","\n","    c2 = Conv2D(64, (3, 3), activation='relu', padding='same')(p1)\n","    c2 = Conv2D(64, (3, 3), activation='relu', padding='same')(c2)\n","    p2 = MaxPooling2D((2, 2))(c2)\n","\n","    c3 = Conv2D(128, (3, 3), activation='relu', padding='same')(p2)\n","    c3 = Conv2D(128, (3, 3), activation='relu', padding='same')(c3)\n","    p3 = MaxPooling2D((2, 2))(c3)\n","\n","    c4 = Conv2D(256, (3, 3), activation='relu', padding='same')(p3)\n","    c4 = Conv2D(256, (3, 3), activation='relu', padding='same')(c4)\n","    p4 = MaxPooling2D((2, 2))(c4)\n","\n","    c5 = Conv2D(512, (3, 3), activation='relu', padding='same')(p4)\n","    c5 = Conv2D(512, (3, 3), activation='relu', padding='same')(c5)\n","\n","    u6 = UpSampling2D((2, 2))(c5)\n","    u6 = concatenate([u6, c4])\n","    c6 = Conv2D(256, (3, 3), activation='relu', padding='same')(u6)\n","    c6 = Conv2D(256, (3, 3), activation='relu', padding='same')(c6)\n","\n","    u7 = UpSampling2D((2, 2))(c6)\n","    u7 = concatenate([u7, c3])\n","    c7 = Conv2D(128, (3, 3), activation='relu', padding='same')(u7)\n","    c7 = Conv2D(128, (3, 3), activation='relu', padding='same')(c7)\n","\n","    u8 = UpSampling2D((2, 2))(c7)\n","    u8 = concatenate([u8, c2])\n","    c8 = Conv2D(64, (3, 3), activation='relu', padding='same')(u8)\n","    c8 = Conv2D(64, (3, 3), activation='relu', padding='same')(c8)\n","\n","    u9 = UpSampling2D((2, 2))(c8)\n","    u9 = concatenate([u9, c1])\n","    c9 = Conv2D(32, (3, 3), activation='relu', padding='same')(u9)\n","    c9 = Conv2D(32, (3, 3), activation='relu', padding='same')(c9)\n","\n","    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n","\n","    model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n","    return model\n","\n","# Build and compile the segmentation model\n","segmentation_model = build_segmentation_model((IMAGE_SIZE, IMAGE_SIZE, 1))\n","segmentation_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Simulated training data for segmentation (replace with actual data)\n","# Assuming binary segmentation for simplicity\n","train_images = np.random.rand(100, IMAGE_SIZE, IMAGE_SIZE, 1)  # 100 random images\n","train_masks = np.random.randint(0, 2, (100, IMAGE_SIZE, IMAGE_SIZE, 1))  # Random binary masks\n","\n","# Train the segmentation model\n","segmentation_history = segmentation_model.fit(train_images, train_masks, epochs=10, batch_size=8)\n","\n","# Display segmentation results\n","for i in range(3):\n","    test_image = test_generator[i][0][0].numpy().reshape(IMAGE_SIZE, IMAGE_SIZE, 1)\n","    predicted_mask = segmentation_model.predict(test_image[np.newaxis, ...])\n","    plt.subplot(1, 2, 1)\n","    plt.imshow(test_image.reshape(IMAGE_SIZE, IMAGE_SIZE), cmap='gray')\n","    plt.title('Original Image')\n","    plt.axis('off')\n","\n","    plt.subplot(1, 2, 2)\n","    plt.imshow(predicted_mask[0].reshape(IMAGE_SIZE, IMAGE_SIZE), cmap='gray')\n","    plt.title('Predicted Segmentation Mask')\n","    plt.axis('off')\n","    plt.show()"],"metadata":{"id":"U6-7JlBbuWUR"},"execution_count":null,"outputs":[]}]}