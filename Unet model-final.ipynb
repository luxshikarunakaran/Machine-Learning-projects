{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"-XIRVGYZlttp"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Found 613 files belonging to 4 classes.\n","Found 72 files belonging to 4 classes.\n","Found 315 files belonging to 4 classes.\n","Epoch 1/5\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208s/step - accuracy: 0.2517 - loss: 318.8781  \n","Epoch 1: val_loss improved from inf to 1.37874, saving model to chestmodel_unet.keras\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4343s\u001b[0m 216s/step - accuracy: 0.2524 - loss: 309.8278 - val_accuracy: 0.1806 - val_loss: 1.3787\n","Epoch 2/5\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208s/step - accuracy: 0.2762 - loss: 1.3565  \n","Epoch 2: val_loss improved from 1.37874 to 1.34420, saving model to chestmodel_unet.keras\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4315s\u001b[0m 215s/step - accuracy: 0.2768 - loss: 1.3560 - val_accuracy: 0.5000 - val_loss: 1.3442\n","Epoch 3/5\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 205s/step - accuracy: 0.3267 - loss: 1.3163  \n","Epoch 3: val_loss improved from 1.34420 to 1.25093, saving model to chestmodel_unet.keras\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4259s\u001b[0m 213s/step - accuracy: 0.3278 - loss: 1.3161 - val_accuracy: 0.4583 - val_loss: 1.2509\n","Epoch 4/5\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 206s/step - accuracy: 0.3503 - loss: 1.2549  \n","Epoch 4: val_loss improved from 1.25093 to 1.17198, saving model to chestmodel_unet.keras\n","\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4276s\u001b[0m 214s/step - accuracy: 0.3513 - loss: 1.2546 - val_accuracy: 0.4861 - val_loss: 1.1720\n","Epoch 5/5\n","\u001b[1m 3/20\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:00:18\u001b[0m 213s/step - accuracy: 0.5000 - loss: 1.0619"]}],"source":["# -*- coding: utf-8 -*-\n","\"\"\"UNet_Classification.ipynb\"\"\"\n","\n","import tensorflow.keras as keras\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dense, Dropout, GlobalAveragePooling2D\n","from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n","from tensorflow.keras import optimizers\n","import tensorflow as tf\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import cv2\n","import os\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Paths\n","train_path = \"/content/drive/MyDrive/Data/train\"\n","valid_path = \"/content/drive/MyDrive/Data/valid\"\n","test_path = \"/content/drive/MyDrive/Data/test\"\n","\n","# Constants\n","IMAGE_SIZE = 224\n","N_CLASSES = 4\n","BATCH_SIZE = 32\n","\n","# Data generators\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255.,\n","    rotation_range=10,\n","    width_shift_range=0.3,\n","    height_shift_range=0.3,\n","    shear_range=0.2,\n","    zoom_range=0.1,\n","    horizontal_flip=True,\n","    vertical_flip=True,\n","    dtype='float32'\n",")\n","train_generator = tf.keras.preprocessing.image_dataset_from_directory(\n","    train_path,\n","    shuffle=True,\n","    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n","    batch_size=BATCH_SIZE,\n","    color_mode=\"grayscale\"\n",")\n","\n","valid_datagen = ImageDataGenerator(dtype='float32', rescale=1./255.)\n","valid_generator = tf.keras.preprocessing.image_dataset_from_directory(\n","    valid_path,\n","    shuffle=True,\n","    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n","    batch_size=BATCH_SIZE,\n","    color_mode=\"grayscale\"\n",")\n","\n","test_datagen = ImageDataGenerator(dtype='float32', rescale=1.0/255.0)\n","test_generator = tf.keras.preprocessing.image_dataset_from_directory(\n","    test_path,\n","    shuffle=True,\n","    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n","    batch_size=BATCH_SIZE,\n","    color_mode=\"grayscale\"\n",")\n","\n","test_class_names = test_generator.class_names\n","\n","# Convert grayscale to RGB function\n","def convert_to_rgb(images):\n","    return tf.image.grayscale_to_rgb(images) if images.shape[-1] == 1 else images\n","\n","# Build U-Net model for classification\n","def build_unet_model(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3), n_classes=N_CLASSES):\n","    inputs = Input(input_shape)\n","\n","    # Encoder (Downsampling)\n","    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n","    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n","    p1 = MaxPooling2D((2, 2))(c1)\n","\n","    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n","    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n","    p2 = MaxPooling2D((2, 2))(c2)\n","\n","    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n","    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n","    p3 = MaxPooling2D((2, 2))(c3)\n","\n","    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n","    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n","    p4 = MaxPooling2D((2, 2))(c4)\n","\n","    # Bottleneck\n","    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n","    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n","\n","    # Decoder (Upsampling)\n","    u6 = UpSampling2D((2, 2))(c5)\n","    u6 = concatenate([u6, c4])\n","    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n","    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n","\n","    u7 = UpSampling2D((2, 2))(c6)\n","    u7 = concatenate([u7, c3])\n","    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n","    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n","\n","    u8 = UpSampling2D((2, 2))(c7)\n","    u8 = concatenate([u8, c2])\n","    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n","    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n","\n","    u9 = UpSampling2D((2, 2))(c8)\n","    u9 = concatenate([u9, c1])\n","    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n","    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n","\n","    # Classification head\n","    x = GlobalAveragePooling2D()(c9)\n","    x = Dense(128, activation='relu')(x)\n","    x = Dropout(0.5)(x)\n","    outputs = Dense(n_classes, activation='softmax')(x)\n","\n","    model = Model(inputs, outputs)\n","    return model\n","\n","# Build and compile the model\n","model = build_unet_model(input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n","\n","# Callbacks\n","checkpointer = ModelCheckpoint('chestmodel_unet.keras', verbose=1, save_best_only=True)\n","early_stopping = EarlyStopping(monitor='val_loss', patience=10)\n","\n","# Train the model\n","history = model.fit(\n","    train_generator.map(lambda x, y: (convert_to_rgb(x), y)),\n","    epochs=5,\n","    validation_data=valid_generator.map(lambda x, y: (convert_to_rgb(x), y)),\n","    callbacks=[checkpointer, early_stopping]\n",")\n","\n","# Evaluate the model\n","train_result = model.evaluate(train_generator.map(lambda x, y: (convert_to_rgb(x), y)))\n","print(f'Training Loss: {train_result[0]}, Training Accuracy: {train_result[1]}')\n","\n","test_result = model.evaluate(test_generator.map(lambda x, y: (convert_to_rgb(x), y)))\n","print(f'Test Loss: {test_result[0]}, Test Accuracy: {test_result[1]}')\n","\n","# Predictions and Evaluation\n","y_true = []\n","for _, labels in test_generator:\n","    y_true.extend(labels.numpy())\n","y_true = np.array(y_true)\n","\n","y_pred = model.predict(test_generator.map(lambda x, y: (convert_to_rgb(x), y)))\n","y_pred_classes = np.argmax(y_pred, axis=1)\n","\n","class_names = ['Adenocarcinoma', 'Squamous Cell Carcinoma', 'Large Cell Carcinoma', 'Small Cell Lung Cancer']\n","\n","print(\"Classification Report:\")\n","print(classification_report(y_true, y_pred_classes, target_names=class_names))\n","\n","conf_matrix = confusion_matrix(y_true, y_pred_classes)\n","plt.figure(figsize=(10, 7))\n","sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n","            xticklabels=class_names, yticklabels=class_names)\n","plt.ylabel('Actual')\n","plt.xlabel('Predicted')\n","plt.title('Confusion Matrix')\n","plt.show()\n","\n","# ROC Curves\n","fpr = {}\n","tpr = {}\n","roc_auc = {}\n","for i in range(N_CLASSES):\n","    fpr[i], tpr[i], _ = roc_curve(y_true == i, y_pred[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","plt.figure()\n","for i in range(N_CLASSES):\n","    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f) for class %s' % (roc_auc[i], class_names[i]))\n","plt.plot([0, 1], [0, 1], 'k--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic')\n","plt.legend(loc=\"lower right\")\n","plt.show()\n","\n","# Single image prediction function\n","def predict(model, img):\n","    img_array = tf.keras.preprocessing.image.img_to_array(img)\n","    img_array = convert_to_rgb(img_array)\n","    img_array = tf.image.resize(img_array, (IMAGE_SIZE, IMAGE_SIZE))\n","    img_array = tf.expand_dims(img_array, 0)\n","    predictions = model.predict(img_array)\n","    predicted_class = test_class_names[np.argmax(predictions[0])]\n","    confidence = round(100 * (np.max(predictions[0])), 2)\n","    return predicted_class, confidence\n","\n","# CT Scan analysis with U-Net\n","classifier = tf.keras.models.load_model('chestmodel_unet.keras')\n","class_labels = ['adenocarcinoma', 'large_cell_carcinoma', 'normal', 'squamous_cell_carcinoma']\n","\n","# Define the model's testing accuracy (replace with actual value)\n","MODEL_ACCURACY = 85.0  # Example: 85% accuracy, update with your model's test accuracy\n","\n","# Function to preprocess the image for prediction\n","def preprocess_for_prediction(img):\n","    img = cv2.resize(img, (224, 224))\n","    img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n","    img = img.astype('float32')\n","    img = img / 255.0  # Simple rescaling since U-Net doesn't use MobileNet preprocessing\n","    img = np.expand_dims(img, axis=0)\n","    return img\n","\n","# Load the CT scan image\n","image_path = '/content/drive/MyDrive/Data/test/adenocarcinoma/000109 (2).png'\n","image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","\n","if image is None:\n","    print(\"Error: Unable to load the image. Please check the file format and path.\")\n","else:\n","    blurred = cv2.GaussianBlur(image, (5, 5), 0)\n","    _, binary = cv2.threshold(blurred, 50, 255, cv2.THRESH_BINARY)\n","    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n","    output_image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n","    predictions = []\n","\n","    for contour in contours:\n","        area = cv2.contourArea(contour)\n","        if area \u003e 100:\n","            x, y, w, h = cv2.boundingRect(contour)\n","            cv2.rectangle(output_image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n","            cropped_image = image[y:y + h, x:x + w]\n","            preprocessed_image = preprocess_for_prediction(cropped_image)\n","            confidence_scores = classifier.predict(preprocessed_image)[0]\n","            predicted_class_index = np.argmax(confidence_scores)\n","            predicted_class = class_labels[predicted_class_index]\n","            confidence = round(100 * confidence_scores[predicted_class_index], 2)\n","            predictions.append((predicted_class, confidence))\n","            cv2.putText(output_image, f\"{predicted_class} ({confidence}%)\", (x, y - 10),\n","                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n","\n","    plt.figure(figsize=(10, 5))\n","    plt.subplot(1, 2, 1)\n","    plt.title('Original CT Scan')\n","    plt.imshow(image, cmap='gray')\n","    plt.axis('off')\n","\n","    plt.subplot(1, 2, 2)\n","    plt.title('Detected Areas with Predictions')\n","    plt.imshow(output_image)\n","    plt.axis('off')\n","    plt.show()\n","\n","    # Print individual predictions\n","    for i, (pred_class, conf) in enumerate(predictions):\n","        print(f'Detected area {i + 1}: {pred_class} with confidence {conf}%')\n","\n","    # Detection logic incorporating model accuracy\n","    if predictions:\n","        reliable_predictions = [(p, c) for p, c in predictions if c \u003e= MODEL_ACCURACY]\n","\n","        if reliable_predictions:\n","            final_pred_class, final_conf = max(reliable_predictions, key=lambda x: x[1])\n","            print(f'Final prediction result (considering {MODEL_ACCURACY}% model accuracy): '\n","                  f'{final_pred_class} with confidence {final_conf}%')\n","\n","            cancer_types = ['adenocarcinoma', 'large_cell_carcinoma', 'squamous_cell_carcinoma']\n","            if final_pred_class.lower() in cancer_types:\n","                print(f\"Cancer detected: {final_pred_class} with confidence {final_conf}% \"\n","                      f\"(model accuracy: {MODEL_ACCURACY}%)\")\n","            else:\n","                print(f\"No cancer detected: {final_pred_class} with confidence {final_conf}% \"\n","                      f\"(model accuracy: {MODEL_ACCURACY}%)\")\n","\n","            print(f\"The image is classified as: {final_pred_class} with confidence {final_conf}%\")\n","        else:\n","            print(f\"No reliable predictions above model accuracy threshold ({MODEL_ACCURACY}%)\")\n","            print(\"The image type cannot be confidently determined due to low confidence scores.\")\n","    else:\n","        print(\"No significant areas detected.\")\n","        print(\"The image type cannot be determined due to no detectable areas.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"akPtxyjamUHh"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOc2X91hmwqzJ9dwFZCwjoh","mount_file_id":"1OCdbCVuOac7rBfxxBCWZdikGjAIzsWP-","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}